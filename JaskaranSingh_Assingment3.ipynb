{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaskaran7d5/Takneek-precamp/blob/main/JaskaranSingh_Assingment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6toho7uRO7v"
      },
      "source": [
        "# Question 1\n",
        "## Developing an Artificial Neural Network from Scratch.\n",
        "\n",
        "In this notebook, we will be developing a feedforward neural network.\n",
        "\n",
        "We will import the MNIST dataset from keras datsets. The MNIST dataset contains images of 28x28 pixels each having values ranging from 0-255.\n",
        "It has 60000 images in the training set and 10000 images in the test set. However, we will only use the first 10000 images for training and first 1000 images for testing because our code isn't optimized and it takes time to run. We are not looking for accuracy of our network right now, we will be doing that in the next week when we will be implementing the same using Tensorflow.\n",
        "\n",
        "\n",
        "Run the first 3 cells. Your code begins after that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI17X78rktdA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrINntzulT4M",
        "outputId": "bf5149c2-4af6-4913-bdb2-6785275cdbb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As discussed in the class, the images are flattened to a column.\n",
        "\n",
        "Then we are normalizing them by dividing by 255."
      ],
      "metadata": {
        "id": "dr4rLzb9ZBQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jy7CLWCEwfn"
      },
      "outputs": [],
      "source": [
        "train_X=train_X.reshape(60000,784,1)    # flattening\n",
        "test_X=test_X.reshape(10000,784,1)\n",
        "\n",
        "train_y=train_y.reshape(60000,1)\n",
        "test_y=test_y.reshape(10000,1)\n",
        "\n",
        "train_X= train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "train_X=train_X[:10000]         #taking the first 10000 images.\n",
        "train_y=train_y[:10000]\n",
        "test_X=test_X[:1000]\n",
        "test_y=test_y[:1000]\n",
        "train_data=list(zip(train_X,train_y))\n",
        "test_data=list(zip(test_X,test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Write the code for Sigmoid Function."
      ],
      "metadata": {
        "id": "wWwDzh6kZOy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q5a8tGYku-7"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sizes=[784,128,10]\n",
        "for (x,y) in zip(sizes[1:],sizes[:-1]):\n",
        "    print((x,y))\n",
        "weights= [np.random.randn(x,y) for x,y in zip(sizes[1:],sizes[:-1])]\n",
        "for i, weight_matrix in enumerate(weights, 1):\n",
        "    print(f\"Size of weights matrix {i}: {weight_matrix.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCYV2-BG5Rh-",
        "outputId": "49fb499d-9898-4ffd-e825-67bd37531cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 784)\n",
            "(10, 128)\n",
            "Size of weights matrix 1: (128, 784)\n",
            "Size of weights matrix 2: (10, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 The Network\n",
        "\n",
        "We will making a class called Network which has certain functions inside it. The cost function used is Cross-Entropy Loss. You need to code only the first 3. Rest are done for you.  There are various places within the code marked as stop_zone. Read the instructions below the code at those places to check whether your code till there is correct or not."
      ],
      "metadata": {
        "id": "cIJI5SoxbJaq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwsydmyTEt0z"
      },
      "outputs": [],
      "source": [
        "class Network(object):\n",
        "    def __init__(self,sizes): # sizes is a list containing the network.\n",
        "                              # eg : [784,128,10] means input =784 neurons,\n",
        "                              #    1st hidden layer 128 neurons, output 10 neurons.\n",
        "        self.sizes=sizes\n",
        "        self.num_layers=len(sizes)\n",
        "        self.weights= [np.random.randn(x,y) for x,y in zip(sizes[1:],sizes[:-1])]\n",
        "        self.biases= [np.reshape(np.zeros(x),(x,1)) for x in sizes[1:]]#\"...can you do this by understanding the self.weights...\"\n",
        "    def show(self):\n",
        "        print(self.num_layers)\n",
        "        for bias in self.biases:\n",
        "            print(bias.shape)\n",
        "        for weight in self.weights:\n",
        "            print(weight.shape)\n",
        "# stop_zone 1. Comment out all the code below. Select all rows below. Click Ctrl + /.\n",
        "# Include the show function given below above this comment area inside the class.\n",
        "# Run this cell and then run the code with stop_zone 1 written below.\n",
        "# After this testing, don't forget tto remove the comments. Same, select all, Ctrl+/.\n",
        "\n",
        "    def forwardpropagation(self,a):\n",
        "        for b,w in zip(self.biases, self.weights):\n",
        "            a=sigmoid(np.dot(w,a)+b) # sig (w.a +b)\n",
        "            #print(a.shape)\n",
        "        return a\n",
        "\n",
        "# # stop_zone 2. Comment out all the code below. Don't comment out the __init__ method else you will get error.\n",
        "# # Remove comment from print(a.shape) line above. Run this cell. And run the code with stop_zone 2 written below.\n",
        "\n",
        "\n",
        "    def backpropagation(self,x,y):\n",
        "\n",
        "#         # nothing to do in this 3 lines.\n",
        "        y_t = np.zeros((len(y), 10))\n",
        "        y_t[np.arange(len(y)), y] = 1\n",
        "        y_t= y_t.T\n",
        "\n",
        "# #         #nabla_b=dC/db and nabla_w=dC/dw. They are lists of shapes equal to that of bias and weights.\n",
        "        nabla_b=[np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w=[np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "#         # initially, a0 = input.\n",
        "        activation=x\n",
        "        activation_list=[x]\n",
        "\n",
        "#         # step 1 : calculation of delta in last layer\n",
        "\n",
        "#         # write the same forward propagation code here but while doing so store the a's.\n",
        "        for w,b in zip(self.weights,self.biases):\n",
        "            # print(w.shape)\n",
        "            # print(activation_list[-1].shape)\n",
        "            # print(b.shape)\n",
        "            activation= sigmoid(np.dot(w,activation_list[-1])+b)\n",
        "            activation_list.append(activation)\n",
        "        delta= (activation_list[-1]-y)*(activation_list[-1])*(1-activation_list[-1])\n",
        "\n",
        "        # # step 2 : nabla_b and nabla_w relation with delta of last layer\n",
        "\n",
        "        nabla_b[-1]=delta\n",
        "        nabla_w[-1]= np.dot(delta,activation_list[-2].T)\n",
        "\n",
        "        #print(\"{} {}\".format(nabla_b[-1].shape,nabla_w[-1].shape) )\n",
        "# #stop_zone 3 : remove comment from the print statement just above and run the cell for stop_zone3.\n",
        "# # don't forget commenting out.\n",
        "\n",
        "        # step 3 : calculation of delta for hidden layers\n",
        "\n",
        "        for j in range(2,self.num_layers):\n",
        "            sig_der = activation_list[-j]*(1-activation_list[-j])\n",
        "            delta= sig_der*(activation_list[-j]-y)#\"...how is dC/dz2 and dC/dz3 related ? Look i have calculated one term already for you (sig_der)...\"\n",
        "\n",
        "            # step 4 : nabla_b and nabla_w relation with delta of others layers\n",
        "            nabla_b[-j]= delta#\"...again, how is dC/db2 and dC/dz2 related...\"\n",
        "            nabla_w[-j]= np.dot(delta,activation_list[-j-1].T)#\"...how is dC/dw2 and dC/dz2 related...\"\n",
        "\n",
        "# #stop_zone 4 : Run the cell for stop_zone 4.\n",
        "        return (nabla_b,nabla_w)\n",
        "\n",
        "#     # the functions below are complete. If you are fine till stop_zone 4, you can run\n",
        "#     # this whole cell and train, test the data by running the last cell of the question.\n",
        "#     # You may need to wait for around 10 minutes to see the test predictions.\n",
        "    def update_mini_batch(self,mini_batch,lr):\n",
        "        nabla_b=[np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w=[np.zeros(w.shape) for w in self.weights]\n",
        "        for x,y in mini_batch:\n",
        "            delta_b,delta_w= self.backpropagation(x,y)\n",
        "            nabla_b=[nb+ db for nb,db in zip (nabla_b,delta_b)]\n",
        "            nabla_w=[nw+dw for nw,dw in zip(nabla_w,delta_w)]\n",
        "\n",
        "        self.weights=[w- lr*nw/len(mini_batch) for w,nw in zip(self.weights,nabla_w)]\n",
        "        self.biases=[b-lr*nb/len(mini_batch) for b,nb in zip(self.biases,nabla_b)]\n",
        "\n",
        "\n",
        "    def SGD(self, train_data,epochs,mini_batch_size, lr):\n",
        "        n_train= len(train_data)\n",
        "        for i in range(epochs):\n",
        "            random.shuffle(train_data)\n",
        "            mini_batches = [train_data[k:k+ mini_batch_size] for k in range(0,n_train,mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch,lr)\n",
        "\n",
        "            self.predict(train_data)\n",
        "            print(\"Epoch {0} completed.\".format(i+1))\n",
        "\n",
        "    def predict(self,test_data):\n",
        "        test_results = [(np.argmax(self.forwardpropagation(x)),y) for x,y in test_data]\n",
        "        # returns the index of that output neuron which has highest activation\n",
        "\n",
        "        num= sum(int (x==y) for x,y in test_results)\n",
        "        print (\"{0}/{1} classified correctly.\".format(num,len(test_data)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u8cVnGamVgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31148973-bf3e-4551-b880-609e80adbf70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "(128, 1)\n",
            "(64, 1)\n",
            "(10, 1)\n",
            "(128, 784)\n",
            "(64, 128)\n",
            "(10, 64)\n"
          ]
        }
      ],
      "source": [
        "# stop_zone 1\n",
        "\n",
        "# def show(self):\n",
        "#   print(self.num_layers)\n",
        "#   for bias in self.biases:\n",
        "#       print(bias.shape)\n",
        "#   for weight in self.weights:\n",
        "#       print(weight.shape)\n",
        "\n",
        "# Copy this show function from here. Paste it inside that Network Class.\n",
        "# Comment out the show function here. Run this cell.\n",
        "\n",
        "net=Network([784,128,64,10])\n",
        "net.show()\n",
        "\n",
        "# The desired output is :\n",
        "# 4\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "# (128, 784)\n",
        "# (64, 128)\n",
        "# (10, 64)\n",
        "#  If you are getting this, you are correct. Proceed to forwardpropagation.\n",
        "\n",
        "# Keeping the show function over there in the Network class doesn't make any\n",
        "# difference. You may delete it if you wish. Better toss a coin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7EJBF7XsSft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbdb62c-8f3f-45f5-8581-a521e0b26351"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.07621470e-02],\n",
              "       [1.01012765e-02],\n",
              "       [6.97198616e-02],\n",
              "       [9.54244877e-01],\n",
              "       [6.02614381e-04],\n",
              "       [9.58359070e-01],\n",
              "       [9.99964543e-01],\n",
              "       [9.99934232e-01],\n",
              "       [5.63718754e-04],\n",
              "       [9.28397968e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# stop_zone 2\n",
        "# to use this, make sure your data is loaded. Run this cell.\n",
        "net=Network([784,128,64,10])\n",
        "#print(train_X[0])\n",
        "net.forwardpropagation(train_X[0])\n",
        "\n",
        "# The desired output is :\n",
        "# (784, 1)\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "#  If you are getting this, you are correct. Proceed to forwardpropagation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop_zone 3\n",
        "net=Network([784,128,64,10])\n",
        "net.backpropagation(train_X[0],train_y[0])\n",
        "\n",
        "# Desired output : (10,1) (10,64)"
      ],
      "metadata": {
        "id": "FwHWyaKNhIIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4a8516-5de8-4238-ca21-383821166e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[1.37651080e-02],\n",
              "         [2.11823759e-04],\n",
              "         [6.55131026e-05],\n",
              "         [1.31845190e-08],\n",
              "         [1.41356182e-05],\n",
              "         [2.06514628e-01],\n",
              "         [1.43402355e-03],\n",
              "         [8.61484658e-02],\n",
              "         [2.95986544e-10],\n",
              "         [2.04047029e-01],\n",
              "         [1.43347652e-04],\n",
              "         [4.27558401e-06],\n",
              "         [2.96976806e-04],\n",
              "         [2.36879237e-01],\n",
              "         [1.61643299e-04],\n",
              "         [7.26210944e-04],\n",
              "         [2.99235228e-02],\n",
              "         [2.93701945e-05],\n",
              "         [2.01840952e-04],\n",
              "         [4.63598500e-03],\n",
              "         [3.33571119e-04],\n",
              "         [5.37967761e-02],\n",
              "         [7.80360543e-06],\n",
              "         [1.29350321e-07],\n",
              "         [2.15021264e-01],\n",
              "         [7.37966369e-02],\n",
              "         [3.98442786e-03],\n",
              "         [3.22391387e-09],\n",
              "         [9.24978476e-05],\n",
              "         [4.70269143e-04],\n",
              "         [2.45576707e-01],\n",
              "         [1.99227011e-01],\n",
              "         [2.81147694e-02],\n",
              "         [1.56153758e-05],\n",
              "         [1.69727625e-01],\n",
              "         [2.95872974e-07],\n",
              "         [1.84297022e-14],\n",
              "         [1.57135100e-06],\n",
              "         [9.44178089e-10],\n",
              "         [3.93375800e-02],\n",
              "         [2.08299720e-04],\n",
              "         [6.62543997e-03],\n",
              "         [5.23339148e-05],\n",
              "         [1.50628498e-01],\n",
              "         [2.04372635e-03],\n",
              "         [1.24111754e-01],\n",
              "         [1.78945789e-06],\n",
              "         [3.31858075e-02],\n",
              "         [1.26887121e-05],\n",
              "         [7.26111574e-05],\n",
              "         [1.50233077e-02],\n",
              "         [7.77592755e-04],\n",
              "         [1.00325072e-04],\n",
              "         [2.27687041e-06],\n",
              "         [5.49353944e-08],\n",
              "         [1.48143049e-03],\n",
              "         [2.05722689e-04],\n",
              "         [3.16627740e-03],\n",
              "         [1.10039451e-01],\n",
              "         [1.13905559e-04],\n",
              "         [2.34627406e-08],\n",
              "         [7.08158091e-04],\n",
              "         [1.02350668e-01],\n",
              "         [1.43067656e-04],\n",
              "         [5.88545812e-03],\n",
              "         [3.05756170e-08],\n",
              "         [2.21390961e-01],\n",
              "         [1.16835520e-05],\n",
              "         [2.49920701e-01],\n",
              "         [2.24805284e-01],\n",
              "         [7.20634071e-03],\n",
              "         [2.32517536e-06],\n",
              "         [2.54332848e-04],\n",
              "         [6.85046490e-03],\n",
              "         [7.32227804e-03],\n",
              "         [1.77150919e-07],\n",
              "         [4.70950379e-03],\n",
              "         [3.19456390e-06],\n",
              "         [1.71707333e-01],\n",
              "         [3.26382600e-02],\n",
              "         [1.13268726e-01],\n",
              "         [7.73458048e-03],\n",
              "         [1.48190674e-01],\n",
              "         [5.88609444e-02],\n",
              "         [7.21181080e-05],\n",
              "         [3.11193087e-03],\n",
              "         [1.34439877e-03],\n",
              "         [9.72029030e-04],\n",
              "         [2.14797729e-03],\n",
              "         [8.56145277e-02],\n",
              "         [8.42955126e-02],\n",
              "         [8.28464711e-02],\n",
              "         [3.29149163e-02],\n",
              "         [1.25702327e-05],\n",
              "         [1.61021026e-03],\n",
              "         [8.05065185e-07],\n",
              "         [3.12518894e-03],\n",
              "         [5.15859815e-03],\n",
              "         [1.87994739e-01],\n",
              "         [1.09573795e-01],\n",
              "         [6.93867677e-04],\n",
              "         [2.25818798e-01],\n",
              "         [7.85655794e-08],\n",
              "         [9.46335398e-09],\n",
              "         [5.20233792e-03],\n",
              "         [2.58107595e-05],\n",
              "         [2.77974997e-02],\n",
              "         [1.12962461e-02],\n",
              "         [5.58442181e-13],\n",
              "         [2.35480795e-03],\n",
              "         [2.18393873e-01],\n",
              "         [3.98687904e-08],\n",
              "         [3.60452280e-13],\n",
              "         [2.36559124e-01],\n",
              "         [1.76307029e-01],\n",
              "         [4.77802009e-07],\n",
              "         [5.47487678e-07],\n",
              "         [2.38012132e-01],\n",
              "         [1.73338932e-01],\n",
              "         [5.04552548e-05],\n",
              "         [2.43050809e-03],\n",
              "         [1.04052484e-08],\n",
              "         [1.06025587e-02],\n",
              "         [5.06133476e-06],\n",
              "         [2.21899424e-01],\n",
              "         [4.62734052e-04],\n",
              "         [1.38789102e-01],\n",
              "         [3.16543914e-06]]),\n",
              "  array([[2.51775776e-04],\n",
              "         [9.43375203e-08],\n",
              "         [6.73121854e-03],\n",
              "         [2.56657332e-02],\n",
              "         [1.09117786e-04],\n",
              "         [1.78462903e-03],\n",
              "         [8.21384785e-09],\n",
              "         [2.82199439e-04],\n",
              "         [1.96523067e-03],\n",
              "         [1.95835866e-04],\n",
              "         [1.97971666e-01],\n",
              "         [1.28826090e-02],\n",
              "         [2.49848184e-01],\n",
              "         [6.41957013e-04],\n",
              "         [1.35623982e-02],\n",
              "         [2.17920637e-01],\n",
              "         [1.96250057e-07],\n",
              "         [4.70788253e-05],\n",
              "         [7.34292051e-07],\n",
              "         [4.10537955e-02],\n",
              "         [5.56926199e-02],\n",
              "         [8.80554966e-06],\n",
              "         [6.00703209e-04],\n",
              "         [4.03387429e-03],\n",
              "         [2.46363145e-03],\n",
              "         [9.18159546e-02],\n",
              "         [1.60149477e-05],\n",
              "         [7.73913038e-08],\n",
              "         [2.16505865e-03],\n",
              "         [5.71337999e-03],\n",
              "         [2.27826757e-03],\n",
              "         [5.90570386e-05],\n",
              "         [1.97019297e-06],\n",
              "         [6.68936887e-04],\n",
              "         [1.12387698e-11],\n",
              "         [1.99211326e-03],\n",
              "         [4.31124957e-03],\n",
              "         [2.05988342e-04],\n",
              "         [2.66052294e-02],\n",
              "         [1.55694186e-02],\n",
              "         [1.85175763e-03],\n",
              "         [6.87143866e-03],\n",
              "         [2.08134672e-01],\n",
              "         [6.75471931e-04],\n",
              "         [2.99137223e-05],\n",
              "         [1.25416697e-01],\n",
              "         [1.07622956e-05],\n",
              "         [4.50525272e-10],\n",
              "         [6.26316763e-07],\n",
              "         [6.52617588e-05],\n",
              "         [1.06266161e-01],\n",
              "         [9.21294384e-05],\n",
              "         [2.39866571e-10],\n",
              "         [8.50779297e-04],\n",
              "         [4.52504329e-04],\n",
              "         [4.36830629e-08],\n",
              "         [1.40528045e-01],\n",
              "         [9.60079089e-05],\n",
              "         [1.08082878e-01],\n",
              "         [2.21349766e-01],\n",
              "         [6.23872806e-04],\n",
              "         [1.85319071e-02],\n",
              "         [2.49523793e-01],\n",
              "         [5.55997470e-11]]),\n",
              "  array([[-4.00152931],\n",
              "         [-4.4569132 ],\n",
              "         [-4.00254843],\n",
              "         [-4.00480443],\n",
              "         [-4.9194036 ],\n",
              "         [-4.00419759],\n",
              "         [-4.97709333],\n",
              "         [-4.97196145],\n",
              "         [-4.98771505],\n",
              "         [-4.01517738]])],\n",
              " [array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
              "  array([[2.48260989e-04, 5.33433931e-08, 2.51759281e-04, ...,\n",
              "          2.51659217e-04, 2.09850824e-04, 2.51774979e-04],\n",
              "         [9.30205695e-08, 1.99871628e-11, 9.43313396e-08, ...,\n",
              "          9.42938469e-08, 7.86287175e-08, 9.43372217e-08],\n",
              "         [6.63725080e-03, 1.42613417e-06, 6.73077752e-03, ...,\n",
              "          6.72810233e-03, 5.61035608e-03, 6.73119723e-03],\n",
              "         ...,\n",
              "         [1.82732018e-02, 3.92633008e-06, 1.85306929e-02, ...,\n",
              "          1.85233277e-02, 1.54460291e-02, 1.85318484e-02],\n",
              "         [2.46040443e-01, 5.28662684e-05, 2.49507445e-01, ...,\n",
              "          2.49408276e-01, 2.07973834e-01, 2.49523003e-01],\n",
              "         [5.48235751e-11, 1.17798432e-14, 5.55961043e-11, ...,\n",
              "          5.55740072e-11, 4.63414428e-11, 5.55995710e-11]]),\n",
              "  array([[-4.00052157e+00, -3.77494389e-07, -2.71189575e-02,\n",
              "          -1.05482774e-01, -4.00109263e+00, -3.99437528e+00,\n",
              "          -3.28679532e-08, -1.12954817e-03, -3.99364987e+00,\n",
              "          -7.83796483e-04, -2.91350230e+00, -5.22319203e-02,\n",
              "          -1.95146037e+00, -3.99895885e+00, -5.50270384e-02,\n",
              "          -1.28406224e+00, -7.85300510e-07, -1.88396169e-04,\n",
              "          -2.93829332e-06, -1.71640245e-01, -3.76465122e+00,\n",
              "          -3.52359754e-05, -2.40517717e-03, -1.62073104e-02,\n",
              "          -3.99164661e+00, -4.09262096e-01, -6.40853089e-05,\n",
              "          -4.00152900e+00, -3.99284693e+00, -2.29943925e-02,\n",
              "          -9.13741962e-03, -2.36332429e-04, -7.88380044e-06,\n",
              "          -2.67856355e-03, -4.49722669e-11, -3.99354187e+00,\n",
              "          -1.73266158e-02, -8.24438247e-04, -3.89207372e+00,\n",
              "          -3.93822640e+00, -3.99410568e+00, -2.76878442e-02,\n",
              "          -1.18201100e+00, -2.70474895e-03, -4.00140961e+00,\n",
              "          -3.41315885e+00, -4.30661048e-05, -1.80279008e-09,\n",
              "          -4.00152681e+00, -4.00126815e+00, -4.83695023e-01,\n",
              "          -4.00116062e+00, -4.00152931e+00, -3.40731964e-03,\n",
              "          -3.99971778e+00, -1.74799064e-07, -6.76796804e-01,\n",
              "          -3.84215353e-04, -4.93312977e-01, -1.32345060e+00,\n",
              "          -3.99903131e+00, -3.92594567e+00, -2.08808672e+00,\n",
              "          -4.00152931e+00],\n",
              "         [-4.45579077e+00, -4.20454179e-07, -3.02051616e-02,\n",
              "          -1.17486974e-01, -4.45642682e+00, -4.44894502e+00,\n",
              "          -3.66084072e-08, -1.25809354e-03, -4.44813706e+00,\n",
              "          -8.72994452e-04, -3.24506604e+00, -5.81760414e-02,\n",
              "          -2.17354137e+00, -4.45405021e+00, -6.12892508e-02,\n",
              "          -1.43019169e+00, -8.74669641e-07, -2.09836117e-04,\n",
              "          -3.27267834e-06, -1.91173327e-01, -4.19307779e+00,\n",
              "          -3.92459161e-05, -2.67889225e-03, -1.80517422e-02,\n",
              "          -4.44590582e+00, -4.55837130e-01, -7.13783748e-05,\n",
              "          -4.45691285e+00, -4.44724274e+00, -2.56112110e-02,\n",
              "          -1.01772805e-02, -2.63227641e-04, -8.78099634e-06,\n",
              "          -2.98339068e-03, -5.00902216e-11, -4.44801677e+00,\n",
              "          -1.92984273e-02, -9.18261349e-04, -4.33500129e+00,\n",
              "          -4.38640626e+00, -4.44864474e+00, -3.08387890e-02,\n",
              "          -1.31652676e+00, -3.01255604e-03, -4.45677987e+00,\n",
              "          -3.80158473e+00, -4.79671335e-05, -2.00795203e-09,\n",
              "          -4.45691041e+00, -4.45662231e+00, -5.38740707e-01,\n",
              "          -4.45650255e+00, -4.45691320e+00, -3.79508101e-03,\n",
              "          -4.45489551e+00, -1.94691628e-07, -7.53817947e-01,\n",
              "          -4.27940006e-04, -5.49453208e-01, -1.47406254e+00,\n",
              "          -4.45413092e+00, -4.37272795e+00, -2.32571613e+00,\n",
              "          -4.45691320e+00],\n",
              "         [-4.00154043e+00, -3.77590529e-07, -2.71258642e-02,\n",
              "          -1.05509639e-01, -4.00211163e+00, -3.99539257e+00,\n",
              "          -3.28763241e-08, -1.12983585e-03, -3.99466698e+00,\n",
              "          -7.83996102e-04, -2.91424432e+00, -5.22452228e-02,\n",
              "          -1.95195737e+00, -3.99997731e+00, -5.50410528e-02,\n",
              "          -1.28438927e+00, -7.85500511e-07, -1.88444150e-04,\n",
              "          -2.93904165e-06, -1.71683958e-01, -3.76561000e+00,\n",
              "          -3.52449493e-05, -2.40578972e-03, -1.62114381e-02,\n",
              "          -3.99266321e+00, -4.09366328e-01, -6.41016302e-05,\n",
              "          -4.00254812e+00, -3.99386383e+00, -2.30002488e-02,\n",
              "          -9.13974675e-03, -2.36392619e-04, -7.88580830e-06,\n",
              "          -2.67924573e-03, -4.49837205e-11, -3.99455895e+00,\n",
              "          -1.73310285e-02, -8.24648217e-04, -3.89306496e+00,\n",
              "          -3.93922939e+00, -3.99512290e+00, -2.76948957e-02,\n",
              "          -1.18231204e+00, -2.70543780e-03, -4.00242869e+00,\n",
              "          -3.41402812e+00, -4.30770729e-05, -1.80324922e-09,\n",
              "          -4.00254592e+00, -4.00228720e+00, -4.83818211e-01,\n",
              "          -4.00217964e+00, -4.00254843e+00, -3.40818742e-03,\n",
              "          -4.00073644e+00, -1.74843582e-07, -6.76969172e-01,\n",
              "          -3.84313205e-04, -4.93438614e-01, -1.32378766e+00,\n",
              "          -4.00004979e+00, -3.92694553e+00, -2.08861852e+00,\n",
              "          -4.00254843e+00],\n",
              "         [-4.00379586e+00, -3.77803355e-07, -2.71411534e-02,\n",
              "          -1.05569108e-01, -4.00436739e+00, -3.99764454e+00,\n",
              "          -3.28948545e-08, -1.13047267e-03, -3.99691854e+00,\n",
              "          -7.84437994e-04, -2.91588691e+00, -5.22746704e-02,\n",
              "          -1.95305758e+00, -4.00223187e+00, -5.50720762e-02,\n",
              "          -1.28511320e+00, -7.85943252e-07, -1.88550365e-04,\n",
              "          -2.94069822e-06, -1.71780726e-01, -3.76773246e+00,\n",
              "          -3.52648148e-05, -2.40714572e-03, -1.62205755e-02,\n",
              "          -3.99491364e+00, -4.09597063e-01, -6.41377606e-05,\n",
              "          -4.00480412e+00, -3.99611494e+00, -2.30132127e-02,\n",
              "          -9.14489829e-03, -2.36525859e-04, -7.89025306e-06,\n",
              "          -2.68075587e-03, -4.50090752e-11, -3.99681045e+00,\n",
              "          -1.73407970e-02, -8.25113022e-04, -3.89525925e+00,\n",
              "          -3.94144970e+00, -3.99737472e+00, -2.77105057e-02,\n",
              "          -1.18297844e+00, -2.70696270e-03, -4.00468463e+00,\n",
              "          -3.41595241e+00, -4.31013529e-05, -1.80426561e-09,\n",
              "          -4.00480192e+00, -4.00454305e+00, -4.84090911e-01,\n",
              "          -4.00443544e+00, -4.00480443e+00, -3.41010842e-03,\n",
              "          -4.00299142e+00, -1.74942131e-07, -6.77350740e-01,\n",
              "          -3.84529820e-04, -4.93716737e-01, -1.32453380e+00,\n",
              "          -4.00230438e+00, -3.92915892e+00, -2.08979575e+00,\n",
              "          -4.00480443e+00],\n",
              "         [-4.91816470e+00, -4.64084381e-07, -3.33395276e-02,\n",
              "          -1.29678505e-01, -4.91886675e+00, -4.91060857e+00,\n",
              "          -4.04072330e-08, -1.38864492e-03, -4.90971676e+00,\n",
              "          -9.63584405e-04, -3.58180401e+00, -6.42129238e-02,\n",
              "          -2.39908806e+00, -4.91624353e+00, -6.76491885e-02,\n",
              "          -1.57860156e+00, -9.65433426e-07, -2.31610647e-04,\n",
              "          -3.61228161e-06, -2.11011234e-01, -4.62819020e+00,\n",
              "          -4.33184342e-05, -2.95687880e-03, -1.99249574e-02,\n",
              "          -4.90725400e+00, -5.03138993e-01, -7.87852530e-05,\n",
              "          -4.91940322e+00, -4.90872964e+00, -2.82688663e-02,\n",
              "          -1.12333689e-02, -2.90542568e-04, -9.69219347e-06,\n",
              "          -3.29297480e-03, -5.52880448e-11, -4.90958399e+00,\n",
              "          -2.13010100e-02, -1.01354861e-03, -4.78484099e+00,\n",
              "          -4.84158021e+00, -4.91027713e+00, -3.40389060e-02,\n",
              "          -1.45314172e+00, -3.32516663e-03, -4.91925644e+00,\n",
              "          -4.19607221e+00, -5.29446455e-05, -2.21631565e-09,\n",
              "          -4.91940052e+00, -4.91908253e+00, -5.94645409e-01,\n",
              "          -4.91895034e+00, -4.91940360e+00, -4.18889360e-03,\n",
              "          -4.91717654e+00, -2.14894626e-07, -8.32041046e-01,\n",
              "          -4.72347006e-04, -6.06469538e-01, -1.62702485e+00,\n",
              "          -4.91633260e+00, -4.82648251e+00, -2.56705388e+00,\n",
              "          -4.91940360e+00],\n",
              "         [-4.00318917e+00, -3.77746107e-07, -2.71370408e-02,\n",
              "          -1.05553112e-01, -4.00376061e+00, -3.99703878e+00,\n",
              "          -3.28898700e-08, -1.13030137e-03, -3.99631289e+00,\n",
              "          -7.84319130e-04, -2.91544507e+00, -5.22667493e-02,\n",
              "          -1.95276163e+00, -4.00162541e+00, -5.50637312e-02,\n",
              "          -1.28491847e+00, -7.85824159e-07, -1.88521794e-04,\n",
              "          -2.94025262e-06, -1.71754697e-01, -3.76716154e+00,\n",
              "          -3.52594712e-05, -2.40678097e-03, -1.62181176e-02,\n",
              "          -3.99430830e+00, -4.09534998e-01, -6.41280419e-05,\n",
              "          -4.00419728e+00, -3.99550941e+00, -2.30097255e-02,\n",
              "          -9.14351257e-03, -2.36490019e-04, -7.88905746e-06,\n",
              "          -2.68034966e-03, -4.50022550e-11, -3.99620482e+00,\n",
              "          -1.73381694e-02, -8.24987994e-04, -3.89466901e+00,\n",
              "          -3.94085246e+00, -3.99676900e+00, -2.77063068e-02,\n",
              "          -1.18279918e+00, -2.70655251e-03, -4.00407780e+00,\n",
              "          -3.41543479e+00, -4.30948219e-05, -1.80399221e-09,\n",
              "          -4.00419508e+00, -4.00393625e+00, -4.84017557e-01,\n",
              "          -4.00382865e+00, -4.00419759e+00, -3.40959169e-03,\n",
              "          -4.00238485e+00, -1.74915623e-07, -6.77248102e-01,\n",
              "          -3.84471553e-04, -4.93641925e-01, -1.32433310e+00,\n",
              "          -4.00169792e+00, -3.92856354e+00, -2.08947909e+00,\n",
              "          -4.00419759e+00],\n",
              "         [-4.97583990e+00, -4.69526687e-07, -3.37304994e-02,\n",
              "          -1.31199242e-01, -4.97655018e+00, -4.96819515e+00,\n",
              "          -4.08810876e-08, -1.40492953e-03, -4.96729289e+00,\n",
              "          -9.74884335e-04, -3.62380773e+00, -6.49659471e-02,\n",
              "          -2.42722210e+00, -4.97389619e+00, -6.84425089e-02,\n",
              "          -1.59711378e+00, -9.76755040e-07, -2.34326739e-04,\n",
              "          -3.65464275e-06, -2.13485757e-01, -4.68246487e+00,\n",
              "          -4.38264284e-05, -2.99155405e-03, -2.01586168e-02,\n",
              "          -4.96480124e+00, -5.09039292e-01, -7.97091657e-05,\n",
              "          -4.97709294e+00, -4.96629419e+00, -2.86003746e-02,\n",
              "          -1.13651023e-02, -2.93949754e-04, -9.80585358e-06,\n",
              "          -3.33159143e-03, -5.59364063e-11, -4.96715856e+00,\n",
              "          -2.15508064e-02, -1.02543447e-03, -4.84095270e+00,\n",
              "          -4.89835730e+00, -4.96785982e+00, -3.44380794e-02,\n",
              "          -1.47018267e+00, -3.36416077e-03, -4.97694444e+00,\n",
              "          -4.24527944e+00, -5.35655260e-05, -2.24230633e-09,\n",
              "          -4.97709021e+00, -4.97676849e+00, -6.01618801e-01,\n",
              "          -4.97663475e+00, -4.97709332e+00, -4.23801665e-03,\n",
              "          -4.97484015e+00, -2.17414690e-07, -8.41798371e-01,\n",
              "          -4.77886208e-04, -6.13581591e-01, -1.64610494e+00,\n",
              "          -4.97398631e+00, -4.88308255e+00, -2.59715766e+00,\n",
              "          -4.97709332e+00],\n",
              "         [-4.97070931e+00, -4.69042558e-07, -3.36957200e-02,\n",
              "          -1.31063962e-01, -4.97141886e+00, -4.96307245e+00,\n",
              "          -4.08389352e-08, -1.40348090e-03, -4.96217112e+00,\n",
              "          -9.73879133e-04, -3.62007123e+00, -6.48989608e-02,\n",
              "          -2.42471940e+00, -4.96876761e+00, -6.83719379e-02,\n",
              "          -1.59546700e+00, -9.75747909e-07, -2.34085125e-04,\n",
              "          -3.65087445e-06, -2.13265632e-01, -4.67763678e+00,\n",
              "          -4.37812390e-05, -2.98846946e-03, -2.01378313e-02,\n",
              "          -4.95968204e+00, -5.08514422e-01, -7.96269777e-05,\n",
              "          -4.97196106e+00, -4.96117345e+00, -2.85708848e-02,\n",
              "          -1.13533838e-02, -2.93646662e-04, -9.79574277e-06,\n",
              "          -3.32815623e-03, -5.58787303e-11, -4.96203693e+00,\n",
              "          -2.15285854e-02, -1.02437715e-03, -4.83596120e+00,\n",
              "          -4.89330660e+00, -4.96273747e+00, -3.44025704e-02,\n",
              "          -1.46866677e+00, -3.36069199e-03, -4.97181271e+00,\n",
              "          -4.24090214e+00, -5.35102947e-05, -2.23999429e-09,\n",
              "          -4.97195833e+00, -4.97163695e+00, -6.00998473e-01,\n",
              "          -4.97150334e+00, -4.97196145e+00, -4.23364683e-03,\n",
              "          -4.96971060e+00, -2.17190514e-07, -8.40930393e-01,\n",
              "          -4.77393460e-04, -6.12948928e-01, -1.64440764e+00,\n",
              "          -4.96885764e+00, -4.87804761e+00, -2.59447973e+00,\n",
              "          -4.97196145e+00],\n",
              "         [-4.98645895e+00, -4.70528715e-07, -3.38024845e-02,\n",
              "          -1.31479237e-01, -4.98717075e+00, -4.97879789e+00,\n",
              "          -4.09683329e-08, -1.40792782e-03, -4.97789370e+00,\n",
              "          -9.76964858e-04, -3.63154138e+00, -6.51045925e-02,\n",
              "          -2.43240209e+00, -4.98451110e+00, -6.85885736e-02,\n",
              "          -1.60052222e+00, -9.78839556e-07, -2.34826821e-04,\n",
              "          -3.66244221e-06, -2.13941362e-01, -4.69245783e+00,\n",
              "          -4.39199594e-05, -2.99793839e-03, -2.02016378e-02,\n",
              "          -4.97539674e+00, -5.10125644e-01, -7.98792749e-05,\n",
              "          -4.98771467e+00, -4.97689288e+00, -2.86614114e-02,\n",
              "          -1.13893569e-02, -2.94577078e-04, -9.82678048e-06,\n",
              "          -3.33870146e-03, -5.60557815e-11, -4.97775909e+00,\n",
              "          -2.15967985e-02, -1.02762288e-03, -4.85128389e+00,\n",
              "          -4.90881099e+00, -4.97846185e+00, -3.45115745e-02,\n",
              "          -1.47332022e+00, -3.37134031e-03, -4.98756585e+00,\n",
              "          -4.25433939e+00, -5.36798415e-05, -2.24709168e-09,\n",
              "          -4.98771193e+00, -4.98738953e+00, -6.02902730e-01,\n",
              "          -4.98725550e+00, -4.98771505e+00, -4.24706110e-03,\n",
              "          -4.98545707e+00, -2.17878680e-07, -8.43594872e-01,\n",
              "          -4.78906076e-04, -6.14891050e-01, -1.64961793e+00,\n",
              "          -4.98460141e+00, -4.89350365e+00, -2.60270031e+00,\n",
              "          -4.98771505e+00],\n",
              "         [-4.01416620e+00, -3.78781914e-07, -2.72114525e-02,\n",
              "          -1.05842546e-01, -4.01473921e+00, -4.00799895e+00,\n",
              "          -3.29800564e-08, -1.13340074e-03, -4.00727107e+00,\n",
              "          -7.86469789e-04, -2.92343943e+00, -5.24100684e-02,\n",
              "          -1.95811625e+00, -4.01259816e+00, -5.52147199e-02,\n",
              "          -1.28844181e+00, -7.87978945e-07, -1.89038735e-04,\n",
              "          -2.94831500e-06, -1.72225660e-01, -3.77749136e+00,\n",
              "          -3.53561552e-05, -2.41338054e-03, -1.62625888e-02,\n",
              "          -4.00526098e+00, -4.10657972e-01, -6.43038855e-05,\n",
              "          -4.01517707e+00, -4.00646539e+00, -2.30728198e-02,\n",
              "          -9.16858474e-03, -2.37138491e-04, -7.91068982e-06,\n",
              "          -2.68769937e-03, -4.51256544e-11, -4.00716270e+00,\n",
              "          -1.73857119e-02, -8.27250170e-04, -3.90534847e+00,\n",
              "          -3.95165856e+00, -4.00772843e+00, -2.77822795e-02,\n",
              "          -1.18604250e+00, -2.71397407e-03, -4.01505727e+00,\n",
              "          -3.42480016e+00, -4.32129909e-05, -1.80893889e-09,\n",
              "          -4.01517487e+00, -4.01491533e+00, -4.85344768e-01,\n",
              "          -4.01480743e+00, -4.01517738e+00, -3.41894103e-03,\n",
              "          -4.01335968e+00, -1.75395254e-07, -6.79105164e-01,\n",
              "          -3.85525801e-04, -4.94995526e-01, -1.32796451e+00,\n",
              "          -4.01267086e+00, -3.93933594e+00, -2.09520859e+00,\n",
              "          -4.01517738e+00]])])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net=Network([784,128,64,10])\n",
        "nabla_b,nabla_w=net.backpropagation(train_X[0],train_y[0])\n",
        "for nb in nabla_b:\n",
        "  print(nb.shape)\n",
        "for nw in nabla_w:\n",
        "  print(nw.shape)\n",
        "\n",
        "# Desired output:\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "# (128, 784)\n",
        "# (64, 128)\n",
        "# (10, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pq4E3rHik-f",
        "outputId": "e6abcc7d-e529-4931-8e2c-1271f98b13d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 1)\n",
            "(64, 1)\n",
            "(10, 1)\n",
            "(128, 784)\n",
            "(64, 128)\n",
            "(10, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXljiAYRlvdq",
        "outputId": "111ea455-b5bd-4d2d-da6c-17787768aaaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "991/10000 classified correctly.\n",
            "Epoch 1 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 2 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 3 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 4 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 5 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 6 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 7 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 8 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 9 completed.\n",
            "991/10000 classified correctly.\n",
            "Epoch 10 completed.\n",
            "Test data:\n",
            "116/1000 classified correctly.\n"
          ]
        }
      ],
      "source": [
        "net=Network([784,128,64,10])\n",
        "net.SGD(train_data=train_data,epochs=10,mini_batch_size=20,lr=0.01)\n",
        "print(\"Test data:\")\n",
        "net.predict(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End of question 1."
      ],
      "metadata": {
        "id": "mhMIoFT9m7OU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2 :\n",
        "## Stochastic Gradient Descent\n",
        "Implement logistic regression using \"Stochastic gradient descent\" and use iris-dataset as training data.\n",
        "\n",
        "\n",
        "The word 'stochastic' means a system or process linked with a random probability. Hence, in Stochastic Gradient Descent, a few samples are selected randomly instead of the whole data set for each iteration. In Gradient Descent, there is a term called “batch” which denotes the total number of samples from a dataset that is used for calculating the gradient for each iteration. In typical Gradient Descent optimization, like Batch Gradient Descent, the batch is taken to be the whole dataset. Although using the whole dataset is really useful for getting to the minima in a less noisy and less random manner, the problem arises when our dataset gets big.\n",
        "Suppose, you have a million samples in your dataset, so if you use a typical Gradient Descent optimization technique, you will have to use all of the one million samples for completing one iteration while performing the Gradient Descent, and it has to be done for every iteration until the minima are reached. Hence, it becomes computationally very expensive to perform.\n",
        "This problem is solved by Stochastic Gradient Descent. In SGD, it uses only a single sample, i.e., a batch size of one, to perform each iteration. The sample is randomly shuffled and selected for performing the iteration.\n",
        "\n",
        "    Stochastic Gradient Descent (SGD) is a variant of the Gradient Descent algorithm used for optimizing machine learning models. In this variant, only one random training example is used to calculate the gradient and update the parameters at each iteration. Here are some of the advantages and disadvantages of using SGD:\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Speed: SGD is faster than other variants of Gradient Descent such as Batch Gradient Descent and Mini-Batch Gradient Descent since it uses only one example to update the parameters.\n",
        "\n",
        "Memory Efficiency: Since SGD updates the parameters for each training example one at a time, it is memory-efficient and can handle large datasets that cannot fit into memory.\n",
        "\n",
        "Avoidance of Local Minima: Due to the noisy updates in SGD, it has the ability to escape from local minima and converge to a global minimum.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Noisy updates: The updates in SGD are noisy and have a high variance, which can make the optimization process less stable and lead to oscillations around the minimum.\n",
        "\n",
        "Slow Convergence: SGD may require more iterations to converge to the minimum since it updates the parameters for each training example one at a time.\n",
        "\n",
        "Sensitivity to Learning Rate: The choice of learning rate can be critical in SGD since using a high learning rate can cause the algorithm to overshoot the minimum, while a low learning rate can make the algorithm converge slowly.\n",
        "\n",
        "Less Accurate: Due to the noisy updates, SGD may not converge to the exact global minimum and can result in a suboptimal solution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "So, in SGD, we find out the gradient of the cost function of a single example at each iteration instead of the sum of the gradient of the cost function of all the examples.\n",
        "\n",
        "In SGD, since only one sample from the dataset is chosen at random for each iteration, the path taken by the algorithm to reach the minima is usually noisier than your typical Gradient Descent algorithm. But that doesn’t matter all that much because the path taken by the algorithm does not matter, as long as we reach the minima and with a significantly shorter training time."
      ],
      "metadata": {
        "id": "Aa_iPRK6nEay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "# pre load sklearn iris datasets\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "Y = iris.target\n",
        "\n",
        "dataset = []\n",
        "\n",
        "\n",
        "target_label = 0 # choose the target label of flower type\n",
        "for index, x in enumerate(X):\n",
        "    transform_label = None\n",
        "    if Y[index]==target_label:\n",
        "      transform_label=0\n",
        "    else:\n",
        "        transform_label=1\n",
        "    x = [x[0], x[2]]\n",
        "    dataset.append((x,transform_label))\n",
        "\n",
        "dataset = np.array(dataset)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def sgd(dataset, w):\n",
        "    #run sgd randomly\n",
        "    index = random.randint(0, len(dataset) - 1)\n",
        "    data=np.array(dataset[index][0])\n",
        "    data= np.reshape(data,(1,2))\n",
        "    y_p  = np.array(dataset[index][1])\n",
        "    y_p= np.reshape(y_p,(1,1))\n",
        "    #print(data.shape,\"  \",w.T.shape)\n",
        "    #print(\"sgd\",np.dot(data,w.T).shape)\n",
        "    return sigmoid(np.dot(data,w.T)),y_p,data\n",
        "def cost(dataset, w):\n",
        "    total_cost = 0\n",
        "    for x,y in dataset:\n",
        "      y_pred = np.dot(x,w.T)\n",
        "      total_cost+=0.5*(y_pred-y)**2\n",
        "    return total_cost/len(dataset)\n",
        "\n",
        "def logistic_regression(dataset):\n",
        "    w = np.random.rand(1,2)\n",
        "    limit = 1500 #update times\n",
        "    eta = 0.1 #update rate\n",
        "    costs = []\n",
        "    for i in range(limit):\n",
        "        a,y,x = sgd(dataset,w)\n",
        "        #print(\"a\",a.shape)\n",
        "        a= np.reshape(a,(1,1))\n",
        "        x=np.reshape(x,(1,2))\n",
        "        y= np.array(y)\n",
        "        dz = a-y.astype(float)\n",
        "        dz= np.reshape(dz,(1,1))\n",
        "        dw =np.dot(x.T,dz)\n",
        "        dw=dw.T\n",
        "        #print(\"dw \",dw.shape)\n",
        "        costs.append(cost(dataset,w))\n",
        "        w =w-eta*dw\n",
        "        #print(w.shape)\n",
        "        eta = eta * 0.98 #decrease update rate\n",
        "        #print(\"iteration done\")\n",
        "    plt.plot(range(limit), costs)\n",
        "    plt.show()\n",
        "    return w,(limit, costs)\n",
        "\n",
        "def main():\n",
        "    #execute\n",
        "    w,(lim,coshs) = logistic_regression(dataset)\n",
        "    #draw\n",
        "    ps = [v[0] for v in dataset]\n",
        "    label = [v[1] for v in dataset]\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(111)\n",
        "    #plot via label\n",
        "    tpx=[]\n",
        "    for index, label_value in enumerate(label):\n",
        "        px=ps[index][0]\n",
        "        py=ps[index][1]\n",
        "        tpx.append(px)\n",
        "        if label_value == 1:\n",
        "            ax1.scatter(px, py, c='b', marker=\"o\", label='O')\n",
        "        else:\n",
        "            ax1.scatter(px, py, c='r', marker=\"x\", label='X')\n",
        "\n",
        "    l = np.linspace(min(tpx),max(tpx))\n",
        "    a =-w[0][0]/w[0][1]\n",
        "    b=w[0][1]\n",
        "    ax1.plot(l, a*l + b, 'g-')\n",
        "    #plt.legend(loc='upper left');\n",
        "    plt.show()\n",
        "\n",
        "    # limit = w[1][0]\n",
        "    # costs = w[1][1]\n",
        "    # w = w[0]\n",
        "\n",
        "    # calculate score\n",
        "    predicted_Y=[]\n",
        "    answer_Y=[]\n",
        "    # for X,Y in dataset:\n",
        "    #     prediction, (ll,cc)= sgd([(X, Y)], w)\n",
        "    #     predicted_Y.append(prediction)\n",
        "    #     answer_Y.append(Y)\n",
        "    # predicted_Y = np.asarray(predicted_Y)\n",
        "    # predicted_Y = predicted_Y > 0.5\n",
        "    # print(answer_Y)\n",
        "    # print(predicted_Y)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "RMgp1wALns9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "outputId": "85df4c6e-2dbc-4759-a23b-254398971682"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-4f604530aa4e>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  dataset = np.array(dataset)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsVUlEQVR4nO3de3xU1b338e9MJpkkkExIIAmBBFJEqYAUQShiFY85Iod6aU/1aCmltE9bLT5I7YPIq8XWWg3a1lI9Fq3nVDmPF6znJRzLqfhQQJEj94uIFy4VIYIBFcmES66znj9ChplkEgLsmZ3M+rxfr3m9Zvbemb3WEJgva//W2h5jjBEAAECCeN1uAAAAsAvhAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJJTP7Qa0FAqFdODAAWVlZcnj8bjdHAAA0AHGGFVXV6uoqEheb/tjG50ufBw4cEDFxcVuNwMAAJyFiooK9e3bt91jOl34yMrKktTU+OzsbJdbAwAAOiIYDKq4uDj8Pd6eThc+mi+1ZGdnEz4AAOhiOlIyQcEpAABIKMIHAABIKMIHAABIKMIHAABIqDMOH6tWrdK1116roqIieTweLV68OLyvvr5es2bN0tChQ9WtWzcVFRXp29/+tg4cOOBkmwEAQBd2xuHj2LFjGjZsmB577LFW+44fP67Nmzdrzpw52rx5s1566SXt2LFD1113nSONBQAAXZ/HGGPO+oc9Hi1atEg33HBDm8ds2LBBo0aN0t69e1VSUnLa9wwGgwoEAqqqqmKqLQAAXcSZfH/HfZ2PqqoqeTwe5eTkxNxfW1ur2tra8OtgMBjvJgEAABfFteC0pqZGs2bN0i233NJmCiovL1cgEAg/WFodAIDkFrfwUV9fr5tuuknGGM2fP7/N42bPnq2qqqrwo6KiIl5NAgAAnUBcLrs0B4+9e/dqxYoV7V778fv98vv98WgGAADohBwPH83BY9euXVq5cqXy8vKcPgUAAOjCzjh8HD16VLt37w6/3rNnj7Zu3arc3Fz17t1b3/jGN7R582YtWbJEjY2NqqyslCTl5uYqLS3NuZafBWOMFrz5oS4qztHFJT1cbQsAALY646m2r732mq688spW26dMmaJf/OIXKi0tjflzK1eu1Lhx4077/vGcavt/1+7VnMXbJUkfzp3o6HsDAGCzuE61HTdunNrLK+ewbEjc3fvyO243AQAA61lzb5djtQ1qCHXeYAQAgC2sCR/bPqoKPz8vv7uLLQEAwG7WhI8vfyFXv7lxmKTOfWkIAIBkZ0348Hg8Ku6R4XYzAACwnjXhAwAAdA6EDwAAkFBWhg8qPgAAcI9V4cPj8bjdBAAArGdV+AAAAO4jfAAAgISyM3xQ9AEAgGusCh+UfAAA4D6rwgcAAHAf4QMAACSUleGDkg8AANxjVfig5AMAAPdZFT4AAID7CB8AACChrAwfxlD1AQCAW6wKH6zzAQCA+6wKHwAAwH2EDwAAkFBWhg8qPgAAcI9l4YOiDwAA3GZZ+AAAAG4jfAAAgIQifAAAgISyMnywxhgAAO6xKnywyBgAAO6zKnwAAAD3ET4AAEBCWRk+DMuMAQDgGqvCByUfAAC4z6rwAQAA3Ef4AAAACWVl+GCdDwAA3GNV+PCw0AcAAK6zKnwAAAD3ET4AAEBCWRk+qPkAAMA9VoUPKj4AAHCfVeEDAAC4j/ABAAASivABAAASyqrwwTIfAAC4z6rwAQAA3Ef4AAAACXXG4WPVqlW69tprVVRUJI/Ho8WLF0ftN8bonnvuUe/evZWRkaGysjLt2rXLqfY6wrDQBwAArjnj8HHs2DENGzZMjz32WMz9Dz30kB555BE9/vjjWrdunbp166bx48erpqbmnBt7rjys9AEAgOt8Z/oDEyZM0IQJE2LuM8Zo3rx5+tnPfqbrr79ekvQf//EfKigo0OLFi3XzzTefW2sBAECX52jNx549e1RZWamysrLwtkAgoNGjR2vNmjVOngoAAHRRZzzy0Z7KykpJUkFBQdT2goKC8L6WamtrVVtbG34dDAadbFJMVHwAAOAe12e7lJeXKxAIhB/FxcVxOxfrfAAA4D5Hw0dhYaEk6eDBg1HbDx48GN7X0uzZs1VVVRV+VFRUONkkAADQyTgaPkpLS1VYWKjly5eHtwWDQa1bt05jxoyJ+TN+v1/Z2dlRDwAAkLzOuObj6NGj2r17d/j1nj17tHXrVuXm5qqkpEQzZszQr371Kw0cOFClpaWaM2eOioqKdMMNNzjZ7nPCMh8AALjnjMPHxo0bdeWVV4Zf33nnnZKkKVOm6Omnn9Zdd92lY8eO6Qc/+IGOHDmiyy67TEuXLlV6erpzrQYAAF3WGYePcePGtbtCqMfj0S9/+Uv98pe/PKeGAQCA5OT6bBcAAGAXK8OHYaUPAABcY1X4YJ0PAADcZ1X4AAAA7iN8AACAhLIyfLDOBwAA7rEqfHhE0QcAAG6zKnwAAAD3ET4AAEBCWRk+KPkAAMA9VoUP1vkAAMB9VoUPAADgPsIHAABIKCvDB+t8AADgHqvCBzUfAAC4z6rwAQAA3Ef4AAAACUX4AAAACWVp+KDiFAAAt1gVPrixHAAA7rMqfAAAAPcRPgAAQEJZGT5YZAwAAPdYFT5YZAwAAPdZFT4AAID7CB8AACChrAwflHwAAOAeq8IHJR8AALjPqvABAADcR/gAAAAJZWX4MCz0AQCAa6wKH6zzAQCA+6wKHwAAwH2EDwAAkFBWhg8qPgAAcI9l4YOiDwAA3GZZ+AAAAG4jfAAAgISyMnywzAcAAO6xKnywzgcAAO6zKnwAAAD3ET4AAEBCWRk+uLcLAADusSp8UPIBAID7rAofAADAfYQPAACQUFaGDyo+AABwj1Xhw8NCHwAAuM7x8NHY2Kg5c+aotLRUGRkZGjBggO677z5mmAAAAEmSz+k3fPDBBzV//nwtWLBAgwcP1saNGzV16lQFAgFNnz7d6dMBAIAuxvHw8eabb+r666/XxIkTJUn9+/fX888/r/Xr1zt9qrPHIAwAAK5x/LLLpZdequXLl2vnzp2SpLfeekurV6/WhAkTYh5fW1urYDAY9YgXKj4AAHCf4yMfd999t4LBoAYNGqSUlBQ1Njbq/vvv16RJk2IeX15ernvvvdfpZgAAgE7K8ZGPP//5z3r22Wf13HPPafPmzVqwYIF+85vfaMGCBTGPnz17tqqqqsKPiooKp5sEAAA6EcdHPmbOnKm7775bN998syRp6NCh2rt3r8rLyzVlypRWx/v9fvn9fqeb0S5KPgAAcI/jIx/Hjx+X1xv9tikpKQqFQk6f6oyxzAcAAO5zfOTj2muv1f3336+SkhINHjxYW7Zs0cMPP6zvfve7Tp8KAAB0QY6Hj0cffVRz5szRj370Ix06dEhFRUX64Q9/qHvuucfpUwEAgC7I8fCRlZWlefPmad68eU6/tWNYbRUAAPfYdW8XVvoAAMB1VoUPAADgPsIHAABIKCvDBxUfAAC4x6rwwTofAAC4z6rwAQAA3Ef4AAAACUX4AAAACWVl+GCNMQAA3GNl+AAAAO4hfAAAgIQifAAAgISyMnwYlhkDAMA1VoUPFhkDAMB9VoUPAADgPsIHAABIKCvDB+t8AADgHqvCh4eiDwAAXGdV+AAAAO4jfAAAgISyMnxQ8gEAgHusCh9UfAAA4D6rwgcAAHAf4QMAACSUneGDog8AAFxjVfhgmQ8AANxnVfgAAADuI3wAAICEsjJ8GIo+AABwjVXhw8NKHwAAuM6q8AEAANxH+AAAAAllZfgwlHwAAOAaq8IH63wAAOA+q8IHAABwH+EDAAAklJXhg5IPAADcY1X4oOQDAAD3WRU+AACA+wgfAAAgoawMH4aFPgAAcI1d4YOiDwAAXGdX+AAAAK4jfAAAgISyMnxQ8QEAgHusCh8eij4AAHCdVeEDAAC4Ly7hY//+/frWt76lvLw8ZWRkaOjQodq4cWM8TgUAALoYn9Nv+Pnnn2vs2LG68sor9corr6hXr17atWuXevTo4fSpzhrLfAAA4B7Hw8eDDz6o4uJiPfXUU+FtpaWlTp/mrHgo+QAAwHWOX3Z5+eWXNXLkSN14443Kz8/X8OHD9eSTT7Z5fG1trYLBYNQDAAAkL8fDxwcffKD58+dr4MCBevXVV3Xbbbdp+vTpWrBgQczjy8vLFQgEwo/i4mKnmwQAADoRj3H4RidpaWkaOXKk3nzzzfC26dOna8OGDVqzZk2r42tra1VbWxt+HQwGVVxcrKqqKmVnZzvZNH16tFYjf/U3SdKHcyc6+t4AANgsGAwqEAh06Pvb8ZGP3r1768ILL4za9sUvflH79u2Lebzf71d2dnbUI14o+QAAwH2Oh4+xY8dqx44dUdt27typfv36OX0qAADQBTkePn784x9r7dq1euCBB7R7924999xz+uMf/6hp06Y5fSoAANAFOR4+LrnkEi1atEjPP/+8hgwZovvuu0/z5s3TpEmTnD7VOXG41AUAAHSQ4+t8SNJXv/pVffWrX43HW58TDwt9AADgOu7tAgAAEorwAQAAEorwAQAAEsra8EG9KQAA7rAqfFBuCgCA+6wKHwAAwH2EDwAAkFDWhg9KPgAAcIdV4YM1xgAAcJ9V4QMAALiP8AEAABLK2vDBjeUAAHCHVeHDw0ofAAC4zqrwAQAA3Ef4AAAACWVt+KDiAwAAd9gVPij5AADAdXaFDwAA4DrCBwAASChrwwfLfAAA4A6rwgf3dgEAwH1WhQ8AAOA+wgcAAEgoa8OHYaUPAABcYVX4oOQDAAD3WRU+AACA+wgfAAAgoawNH6zzAQCAO6wKHx4W+gAAwHVWhQ8AAOA+wgcAAEgowgcAAEgoq8IHFR8AALjPqvABAADcR/gAAAAJZW34YJ0PAADcYVX4YJkPAADcZ1X4AAAA7iN8AACAhLI2fBhR9AEAgBusCh8eVvoAAMB1VoUPAADgPsIHAABIKGvDB+t8AADgDqvCB+t8AADgPqvCBwAAcB/hAwAAJFTcw8fcuXPl8Xg0Y8aMeJ/qjFDyAQCAO+IaPjZs2KAnnnhCF110UTxPAwAAupC4hY+jR49q0qRJevLJJ9WjR494nQYAAHQxcQsf06ZN08SJE1VWVtbucbW1tQoGg1EPAACQvHzxeNOFCxdq8+bN2rBhw2mPLS8v17333huPZgAAgE7I8ZGPiooK3XHHHXr22WeVnp5+2uNnz56tqqqq8KOiosLpJsVkWGUMAABXOD7ysWnTJh06dEgXX3xxeFtjY6NWrVqlf/3Xf1Vtba1SUlLC+/x+v/x+v9PNiIlFxgAAcJ/j4eOqq67S22+/HbVt6tSpGjRokGbNmhUVPAAAgH0cDx9ZWVkaMmRI1LZu3bopLy+v1XYAAGAfa1c4peIDAAB3xGW2S0uvvfZaIk5zWh5R9AEAgNusHfkAAADuIHwAAICEsjZ8sMwHAADusCp8sM4HAADusyp8AAAA91kfPowx+sXL7+jfV+9xuykAAFghIVNtO6WTNR/r9hzW029+KEn63mWl7rUHAABLWDXyEavko+Lw8YS3AwAAm1kVPmI5fKzO7SYAAGAVwgfhAwCAhLI2fJiTRR+fET4AAEgoq8KHJ8ZCH4x8AACQWFaFj1gY+QAAILGsDx+Hj9W63QQAAKxibfhovrfLZ0cZ+QAAIJGsCh+x1vk4XtfY5vHvHKjSM2v3KhTiLnQAADjF2hVOH1z6vqZc2r/dYyY+slqSlJOZqq9eVJSAVgEAkPysDR8LN1Ro4YaKDh27s7JauijODQIAwBJWXXZpT4xZuGG+FD4mAACcYtW3ansBw7RT1uFLaecHAQDAGbEqfJytNEY+AABwDN+qEUwbwx8+LyMfAAA4hfARoa1LL9R8AADgHKu+VWPd2yVSZPZoaAyFn6dS8wEAgGOsCh9noi4ifPi8fEwAADiFb9UIx+oa9KfVe/TR58dV1xAx8uHjYwIAwCl8q0a4f8l7+uWSd/W1P7wZFT5STnO5BgAAdBzhI8Ly9w9Kkj6prtWJ+lP3fAm1twgIAAA4I4SPCDX1p0Y7qk7Uh58TPgAAcA7hI0JNxGhHZPggewAA4BzCR4SG0KmUERU+RPoAAMAp1oWPjtaOHjkecdkl1M6BAADgjFgXPjqKmg8AAOKD8NGGIDUfAADEBeGjDVGXXUgfAAA4xrrw0dHlwqILTgEAgFOsCx8dEchIVbCGkQ8AAOKB8BFDj8yW4cPFxgAAkGSsCx8dCRKBzDRV1zSEXxtGPgAAcIx14aMjsvy+FuHDxcYAAJBkCB8xeDxSNTUfAADEBeEjhhN1japvPBU4qPkAAMA51oePNF/rjyCy2FSi5gMAACdZHz4yUlNabYtc40PisgsAAE6yPnykp8YY+TjREPV6wZt7o2pAAADA2SN8xBj5OFHfGPV6/5ET+t2yXYlqEgAASY3w4WsdPmLZuPdwnFsCAIAdHA8f5eXluuSSS5SVlaX8/HzdcMMN2rFjh9OncYw/1StPB274UpybGf/GAABgAcfDx+uvv65p06Zp7dq1WrZsmerr63X11Vfr2LFjTp/KEem+lA7dbK6jIyQAAKB9PqffcOnSpVGvn376aeXn52vTpk26/PLLnT7dOWsa+fCcdhnT1JSO3g8XAAC0x/Hw0VJVVZUkKTc3N+b+2tpa1dbWhl8Hg8F4NylKemrHRj5SU6wvjwEAwBFx/UYNhUKaMWOGxo4dqyFDhsQ8pry8XIFAIPwoLi6OZ5NaSU9N6VDNB+EDAABnxPUbddq0adq+fbsWLlzY5jGzZ89WVVVV+FFRURHPJrWS7vPK04GxDy67AADgjLhddrn99tu1ZMkSrVq1Sn379m3zOL/fL7/fH69mnFZ6aoo6dN0FAAA4wvGRD2OMbr/9di1atEgrVqxQaWmp06dwlN/n7VD2eGLVB9rzafSMnbqGkI7XNaihMeRIW47VNrQ6BwAAycbx8DFt2jQ988wzeu6555SVlaXKykpVVlbqxIkTTp/KEam+jq3zIUkTH3kj/NwYo8sfWqkL73lV5//sFf3npo/OqR1Haxt01W9f1z/89jV9SAABACQxx8PH/PnzVVVVpXHjxql3797hxwsvvOD0qRzh83b8msvxulPLrh+qrlVlsEaSFDLS/3nxrXNqxyPLd6kyWCNjpPcrEzvjBwCARHK85qOr3X7e5+1YwWlLH3zi3OiEMUaLtuwPvz5UXdvO0QAAdG3Wzx/1neUsls+OORcQtn1UpU8iAsehIOEDAJC8rA8fKV6PGs9itCZ4osGxNvx22c6o14eqaxx7bwAAOhvrw4fP61FjKHb4uG3cgDZ/rrqm3pHz1zeG9D+7P5Ukfe+ypplBXHYBACQzwkc74WN0aa5mjr8g5r6gQ+Hj4yM1agwZ+X1eXTogT5KiLsEAAJBsrA8fKe0sm57m88rbxjzclpdd/L6z+yjf/bhpZku/vEwVZKdLYuQDAJDcrA8f7U219fu8amt3y5GPrPTTTxya/dI2XTNvlVbuOCRjjEIhoydW/V2SdNl5vZSf1bTS62dHa9scjQEAoKsjfLQTPtJSUtoZ+YgOH939TeFjR2W1Pj3aeuTieF2Dnl9fofcrqzX1qQ1aueOQdh06qi37jig91avvX16qvO5+eT1N64Z8FuM9AABIBoSPdqbapvo8UaufRt5crrqm5WWXFH3wyVGNn7dKX35geav3+vDT41Gv39z9WXgp9fMLstQ7kKEUr0d53ZtGP7j0AgBIVtaHjxRvOzUfKV6lRIyMpPtSws9bXnb55Git7v/v9yRJDTEumRw4Er28fF53vyoONwWSktzM8PbmSy/N+7bvr9KDS9/XjY+/6ViRKwAAborbXW27inYvu7S46Zw/NSJ8tCg4PXysTsvfP9Tmex0+Vhf1+pm1e7X/ZCDpl3cqfDTXetz27Gb9+hsXaeZ/bgvvu+2ZTXr2f3257c4AANAFWD/ycbrw0RgxiNE8o8UY0ypMtFTf4k63n7U4fn/ESEjkyEevkyMfkqKChyT9z+7Putzy9QAAtET4aKfmIy3Fq8bQqRDRXPNRXduguhbhoqXIm9BJChehpsWY2luS2y38vPzrQ9t93+ab2Z2JDz45qu37q8I1JgAAuMn6yy7t1nz4vFH1G96ToySfHW1/1EOSauobFchIDb/eUVktSfpSSY7W7zkcdWzkZZfegYxW7/XHySP04NL39fdPjunh/7dTM6+5QN39PmWmtf/H997HQd30+BpV10ZfIrrrmgt02xUD5GljJg8AAPFkffhIbXeqrVcNEdddmo+MnAbbIzNVnx9vXQj6q/9+Tw98bYiy0lNljNHb+6skSV85r2er8FF4cnExqeleM7+6YYh+tni7JGnu14fq6sGFWvbuQf39k2N6cdNHenHTR5KkokC6AplpuuL8Xlq05SM9esvF6uZPUWqKV1f/blWb/Xpo6Q49tHSHvlSco6KcdOVkpqmmvlG5mWnKyUxVitergmy/Nu79XLmZaSoMpCuQkar+ed2U6U9RUSBDGWkpbb4/AADtsT58eNsIH16P5EuJHvlofvrpyZGPi0tyNP9bIzQ6xtTav7x1QH1yMnT3hEHaf+SEqk7UKzXFoxH9e4SP6e736aFvXNSqDZFh5JohhZKkb44uCYeOZgeqanSgqkbvnVwl9aYn1rRqR4/MVM0oO19XnN9Lb/79M2388LBe2rJfkrS14oi2VsT+XNrj83o0rDhHaSleGRnldfOrrjGkmvpG+X1e1TaE5PelyOuRUn1e5WamKWSMGhqN6kOh8JoodQ2hpkdjSEZSysmRGCMpZIyMMTKm+XnT52+MidjfdKxHTX9esdZkaVkh07JmpvX+9n8+1nsAQFfTO5Cuh74xzLXzWx8+2io4TTtZXBpZ89E8E+WzY00jH3nd/UptZ3n29yubQsHHVU11Gr0DGbqgIEtpPq+MMdpyzz/G/PlLSnOV5fepT48M5WSmSZKGl/TQ01Mv0Xee2tDhvl3/pSL99sZh8p08R/+e3fTN0SX6yvk9Ne9vu7Tv8HEZI40qzVXP7mnavPeIPj9ep9qGkL7Qs5v69+ymE3WNOnysTsGaelWdqFdNfaMaQkab9n7e4XYAADqXL/TqdvqD4sj68NFW3UNzKIi87BIOHydHPvK6pUUtPNZSz5MLhn16csGwnt3TlNfdr2U/vlyZab42g0sgI1Wr7rpS6anRlzauOL+XfjRugHp292vMgDz1yvLrlbc/Vq+sphD0zNq9ykzz6bZxAzSkT6DNdn1teF99bXjfNve3xxijv39yVJv3HpEvxSNfilefVNfK7/MqIzVFdY0hpaV4VdPQKGOaRjeOHK+T1+tR6sl1U47VNsjj8SgtxaM0n1epKU1Tmps/ao8kj6fpElTT86bF3rwej7weyaNTrz0ehUdHQsbIoxh/Hh3bFPN3oeWWWL8ulM4A6Gq6+1NPf1AcWR8+UtoY+WieVht52aV5uL15wbDegYzwCEkszeGieaZLcxjpl3f6xNmjW1qrbR6PR3ddMyhq2+Qx/cPPr/piwWnf91x5PB6dl5+l8/Kz4n4uAEBysn6qbUob/21NC498RFx2MUZHaxu0ZNvHkqQ+PTKU2s5smeqaeoVCJlyrkZ/tb/NYAABsYX34aGvIPC3GyEdjSJr87+t09OTU1fwsf5sFq5IUrGnQi5sqtO2jppkuxT0y2zwWAABbWB8+2rrsEqvmwxijLfuOhF9387d/1Sp4ol4vbjw1Q6U4l/ABAADh4zSzXXK6nSrKOVEfvWppN390Qei0KwdEvQ7W1EeNnDDyAQCAheHj7gmDNKjwVLFkW1dNmsPHtCvP08D87pJaL5nercUKo7nd/Hpi8ojw6+qaBtU1nKoZ6duj9eqlAADYxrrwcesVA6LunxK5MFVkEGkuOM1OT9W/TRkZ870yT67yWZzbFCquvrBA4wcX6o27rpTUdNmluR41JzNVOZnuTm0CAKAzsHKqbeR6DpGXXVJTmlbnlBQ1hTbWypmSwvdWeXXG5ao6UR++L0vuyWmytQ0h7Tp4VJL0zPdGcy8VAABk4ciHFL1wVGSwiLzjbOTztma0pKc2HZOZ5ou6IVw3vy88ytEcZrjkAgBAEyvDR6TIYOGLWK00cuSjrVVM2xvJiAwbfXJOLZMOAIDtrAwfkZkhcpGxyOXMI8NHy2XOO6J5NVNJGlyUfcY/DwBAsrIzfCh2kWlmxG3iIy+7pPvOPHxUnryZnCQN6k34AACgmZ3hIyJwRF52yUo/NRsltcVll3YWMo3pF9cNDj/vm0O9BwAAzayc7WJOrfsVddklO+NU+Igc+fB4PEpPTQmv8zGgVzc9esvF7Z7jy1/I0+wJg7Rx7+e67ktFDrUcAICuz87woVPpI3K2SyAifPhaDHVEho+fXztYF3agjuOHVwzQD8+1sQAAJBkrL7tErHiuyJvSBjJOZbGWE1nSIy7D+H1WfmwAADjCym/RUMR1l8hFxi7pnxt+3nIabeSMF/9ZzH4BAABNrAwfkTUfXo9HS/73ZSr/+lBde1HbtRmR4aN5cTEAAHDm7Kz5MNE1H0P6BDSkTyDqmJaXXSJHS/rldotr+wAASGZW/hc+suYjpY05tB5Fb//0aF34eUYal10AADhbloaPyJGP2Me0HPlIsfKTAgDAeVZ+pUaGj47eafbX3ximHpmpeuyb7a/vAQAA2mdpzcfpj2kZSS4/v5c2z/nHDocVAAAQm5UjHx0KHzEyBsEDAIBzZ2X4CHUgfbQsOAUAAM4gfLTwD4PyJUk3jSxOVHMAALCKlTUffXu0fZfZf/v2SB2vb1R3v5UfDQAAcWflN+x5+Vl67JsXqyDb32qf1+sheAAAEEfWfstOvKi3200AAMBKVtZ8AAAA98QtfDz22GPq37+/0tPTNXr0aK1fvz5epwIAAF1IXMLHCy+8oDvvvFM///nPtXnzZg0bNkzjx4/XoUOH4nE6AADQhcQlfDz88MP6/ve/r6lTp+rCCy/U448/rszMTP3pT3+Kx+kAAEAX4nj4qKur06ZNm1RWVnbqJF6vysrKtGbNmlbH19bWKhgMRj0AAEDycjx8fPrpp2psbFRBQUHU9oKCAlVWVrY6vry8XIFAIPwoLmZxLwAAkpnrs11mz56tqqqq8KOiosLtJgEAgDhyfJ2Pnj17KiUlRQcPHozafvDgQRUWFrY63u/3y+9vvdgXAABITo6PfKSlpWnEiBFavnx5eFsoFNLy5cs1ZswYp08HAAC6mLiscHrnnXdqypQpGjlypEaNGqV58+bp2LFjmjp1ajxOBwAAupC4hI9/+Zd/0SeffKJ77rlHlZWV+tKXvqSlS5e2KkIFAAD28RjTzv3lXRAMBhUIBFRVVaXs7Gy3mwMAADrgTL6/XZ/tAgAA7NLp7mrbPBDDYmMAAHQdzd/bHbmg0unCR3V1tSSx2BgAAF1QdXW1AoFAu8d0upqPUCikAwcOKCsrSx6Px9H3DgaDKi4uVkVFhRX1JPQ3udnWX8m+PtPf5JZs/TXGqLq6WkVFRfJ626/q6HQjH16vV3379o3rObKzs5PiD7qj6G9ys62/kn19pr/JLZn6e7oRj2YUnAIAgIQifAAAgISyKnz4/X79/Oc/t+ZeMvQ3udnWX8m+PtPf5GZbfyN1uoJTAACQ3Kwa+QAAAO4jfAAAgIQifAAAgIQifAAAgISyJnw89thj6t+/v9LT0zV69GitX7/e7SadlfLycl1yySXKyspSfn6+brjhBu3YsSPqmJqaGk2bNk15eXnq3r27/vmf/1kHDx6MOmbfvn2aOHGiMjMzlZ+fr5kzZ6qhoSGRXTkrc+fOlcfj0YwZM8Lbkq2/+/fv17e+9S3l5eUpIyNDQ4cO1caNG8P7jTG655571Lt3b2VkZKisrEy7du2Keo/Dhw9r0qRJys7OVk5Ojr73ve/p6NGjie7KaTU2NmrOnDkqLS1VRkaGBgwYoPvuuy/q3hBdvb+rVq3Stddeq6KiInk8Hi1evDhqv1P927Ztm77yla8oPT1dxcXFeuihh+LdtZja6299fb1mzZqloUOHqlu3bioqKtK3v/1tHThwIOo9kqW/Ld16663yeDyaN29e1Pau1F/HGAssXLjQpKWlmT/96U/mnXfeMd///vdNTk6OOXjwoNtNO2Pjx483Tz31lNm+fbvZunWr+ad/+idTUlJijh49Gj7m1ltvNcXFxWb58uVm48aN5stf/rK59NJLw/sbGhrMkCFDTFlZmdmyZYv561//anr27Glmz57tRpc6bP369aZ///7moosuMnfccUd4ezL19/Dhw6Zfv37mO9/5jlm3bp354IMPzKuvvmp2794dPmbu3LkmEAiYxYsXm7feestcd911prS01Jw4cSJ8zDXXXGOGDRtm1q5da9544w1z3nnnmVtuucWNLrXr/vvvN3l5eWbJkiVmz5495sUXXzTdu3c3v//978PHdPX+/vWvfzU//elPzUsvvWQkmUWLFkXtd6J/VVVVpqCgwEyaNMls377dPP/88yYjI8M88cQTiepmWHv9PXLkiCkrKzMvvPCCef/9982aNWvMqFGjzIgRI6LeI1n6G+mll14yw4YNM0VFReZ3v/td1L6u1F+nWBE+Ro0aZaZNmxZ+3djYaIqKikx5ebmLrXLGoUOHjCTz+uuvG2Oa/nKnpqaaF198MXzMe++9ZySZNWvWGGOa/rJ4vV5TWVkZPmb+/PkmOzvb1NbWJrYDHVRdXW0GDhxoli1bZq644opw+Ei2/s6aNctcdtllbe4PhUKmsLDQ/PrXvw5vO3LkiPH7/eb55583xhjz7rvvGklmw4YN4WNeeeUV4/F4zP79++PX+LMwceJE893vfjdq29e//nUzadIkY0zy9bfll5NT/fvDH/5gevToEfX7PGvWLHPBBRfEuUfta+/LuNn69euNJLN3715jTHL296OPPjJ9+vQx27dvN/369YsKH125v+ci6S+71NXVadOmTSorKwtv83q9Kisr05o1a1xsmTOqqqokSbm5uZKkTZs2qb6+Pqq/gwYNUklJSbi/a9as0dChQ1VQUBA+Zvz48QoGg3rnnXcS2PqOmzZtmiZOnBjVLyn5+vvyyy9r5MiRuvHGG5Wfn6/hw4frySefDO/fs2ePKisro/obCAQ0evToqP7m5ORo5MiR4WPKysrk9Xq1bt26xHWmAy699FItX75cO3fulCS99dZbWr16tSZMmCAp+frbklP9W7NmjS6//HKlpaWFjxk/frx27Nihzz//PEG9OTtVVVXyeDzKycmRlHz9DYVCmjx5smbOnKnBgwe32p9s/e2opA8fn376qRobG6O+eCSpoKBAlZWVLrXKGaFQSDNmzNDYsWM1ZMgQSVJlZaXS0tLCf5GbRfa3srIy5ufRvK+zWbhwoTZv3qzy8vJW+5Ktvx988IHmz5+vgQMH6tVXX9Vtt92m6dOna8GCBZJOtbe93+fKykrl5+dH7ff5fMrNze10/b377rt18803a9CgQUpNTdXw4cM1Y8YMTZo0SVLy9bclp/rXlX7HI9XU1GjWrFm65ZZbwjdWS7b+Pvjgg/L5fJo+fXrM/cnW347qdHe1RcdNmzZN27dv1+rVq91uStxUVFTojjvu0LJly5Senu52c+IuFApp5MiReuCBByRJw4cP1/bt2/X4449rypQpLrfOeX/+85/17LPP6rnnntPgwYO1detWzZgxQ0VFRUnZX5xSX1+vm266ScYYzZ8/3+3mxMWmTZv0+9//Xps3b5bH43G7OZ1K0o989OzZUykpKa1mPxw8eFCFhYUuterc3X777VqyZIlWrlypvn37hrcXFhaqrq5OR44ciTo+sr+FhYUxP4/mfZ3Jpk2bdOjQIV188cXy+Xzy+Xx6/fXX9cgjj8jn86mgoCCp+tu7d29deOGFUdu++MUvat++fZJOtbe93+fCwkIdOnQoan9DQ4MOHz7c6fo7c+bM8OjH0KFDNXnyZP34xz8Oj3IlW39bcqp/Xel3XDoVPPbu3atly5ZF3U4+mfr7xhtv6NChQyopKQn/+7V371795Cc/Uf/+/SUlV3/PRNKHj7S0NI0YMULLly8PbwuFQlq+fLnGjBnjYsvOjjFGt99+uxYtWqQVK1aotLQ0av+IESOUmpoa1d8dO3Zo37594f6OGTNGb7/9dtQvfPM/AC2/+Nx21VVX6e2339bWrVvDj5EjR2rSpEnh58nU37Fjx7aaOr1z507169dPklRaWqrCwsKo/gaDQa1bty6qv0eOHNGmTZvCx6xYsUKhUEijR49OQC867vjx4/J6o/8ZSklJUSgUkpR8/W3Jqf6NGTNGq1atUn19ffiYZcuW6YILLlCPHj0S1JuOaQ4eu3bt0t/+9jfl5eVF7U+m/k6ePFnbtm2L+verqKhIM2fO1Kuvviopufp7RtyueE2EhQsXGr/fb55++mnz7rvvmh/84AcmJycnavZDV3HbbbeZQCBgXnvtNfPxxx+HH8ePHw8fc+utt5qSkhKzYsUKs3HjRjNmzBgzZsyY8P7mqadXX3212bp1q1m6dKnp1atXp5x6GkvkbBdjkqu/69evNz6fz9x///1m165d5tlnnzWZmZnmmWeeCR8zd+5ck5OTY/7rv/7LbNu2zVx//fUxp2YOHz7crFu3zqxevdoMHDiw00w9jTRlyhTTp0+f8FTbl156yfTs2dPcdddd4WO6en+rq6vNli1bzJYtW4wk8/DDD5stW7aEZ3c40b8jR46YgoICM3nyZLN9+3azcOFCk5mZ6cpUzPb6W1dXZ6677jrTt29fs3Xr1qh/wyJnciRLf2NpOdvFmK7VX6dYET6MMebRRx81JSUlJi0tzYwaNcqsXbvW7SadFUkxH0899VT4mBMnTpgf/ehHpkePHiYzM9N87WtfMx9//HHU+3z44YdmwoQJJiMjw/Ts2dP85Cc/MfX19QnuzdlpGT6Srb9/+ctfzJAhQ4zf7zeDBg0yf/zjH6P2h0IhM2fOHFNQUGD8fr+56qqrzI4dO6KO+eyzz8wtt9xiunfvbrKzs83UqVNNdXV1IrvRIcFg0Nxxxx2mpKTEpKenmy984Qvmpz/9adQXUVfv78qVK2P+nZ0yZYoxxrn+vfXWW+ayyy4zfr/f9OnTx8ydOzdRXYzSXn/37NnT5r9hK1euDL9HsvQ3lljhoyv11ykeYyKWEgQAAIizpK/5AAAAnQvhAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJBThAwAAJNT/B0A3cQbHUNUBAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3 :\n",
        "## Implement linear regression using \"mini-batch\" gradient descent\n",
        "\n",
        "\n",
        "Mini-Batch Gradient Descent: Parameters are updated after computing the gradient of  the error with respect to a subset of the training set.\n",
        "Thus, mini-batch gradient descent makes a compromise between the speedy convergence and the noise associated with gradient update which makes it a more flexible and robust algorithm.\n",
        "\n",
        "\n",
        " Mini-Batch Gradient Descent: Algorithm-\n",
        "\n",
        "    Let theta = model parameters and max_iters = number of epochs. for itr = 1, 2, 3, …, max_iters:       for mini_batch (X_mini, y_mini):\n",
        "\n",
        "        Forward Pass on the batch X_mini:\n",
        "            Make predictions on the mini-batch\n",
        "            Compute error in predictions (J(theta)) with the current values of the parameters\n",
        "        Backward Pass:\n",
        "            Compute gradient(theta) = partial derivative of J(theta) w.r.t. theta\n",
        "        Update parameters:\n",
        "            theta = theta – learning_rate*gradient(theta)"
      ],
      "metadata": {
        "id": "I1CbSYwCn0BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# creating data\n",
        "mean = np.array([5.0, 6.0])\n",
        "cov = np.array([[1.0, 0.95], [0.95, 1.2]])\n",
        "data = np.random.multivariate_normal(mean, cov, 8000)\n",
        "\n",
        "# visualising data\n",
        "plt.scatter(data[:500, 0], data[:500, 1], marker='.')\n",
        "plt.show()\n",
        "\n",
        "# train-test-split\n",
        "data = np.hstack((np.ones((data.shape[0], 1)), data))\n",
        "\n",
        "split_factor = 0.90\n",
        "split = int(split_factor * data.shape[0])\n",
        "\n",
        "X_train = data[:split, :-1]\n",
        "y_train = data[:split, -1].reshape((-1, 1))\n",
        "X_test = data[split:, :-1]\n",
        "y_test = data[split:, -1].reshape((-1, 1))\n",
        "\n",
        "\n",
        "\n",
        "# linear regression using \"mini-batch\" gradient descent\n",
        "# function to compute hypothesis / predictions\n",
        "\n",
        "\n",
        "def hypothesis(X, theta):\n",
        "\treturn '...'\n",
        "\n",
        "# function to compute gradient of error function w.r.t. theta\n",
        "\n",
        "\n",
        "def gradient(X, y, theta):\n",
        "\t'...'\n",
        "\n",
        "# function to compute the error for current values of theta\n",
        "\n",
        "\n",
        "def cost(X, y, theta):\n",
        "\t'...'\n",
        "\n",
        "# function to create a list containing mini-batches\n",
        "\n",
        "\n",
        "def create_mini_batches(X, y, batch_size):\n",
        "\tmini_batches = []\n",
        "\tdata = np.hstack((X, y))\n",
        "\tnp.random.shuffle(data)\n",
        "\tn_minibatches = data.shape[0] // batch_size\n",
        "\ti = 0\n",
        "\n",
        "\tfor i in range(n_minibatches + 1):\n",
        "\t\t'...'\n",
        "\tif data.shape[0] % batch_size != 0:\n",
        "\t\t'...'\n",
        "\treturn '...'\n",
        "\n",
        "# function to perform mini-batch gradient descent\n",
        "\n",
        "\n",
        "def gradientDescent(X, y, learning_rate=0.001, batch_size=32):\n",
        "\t'...'\n",
        "\n",
        "\n",
        "theta, error_list = gradientDescent(X_train, y_train)\n",
        "print(\"Bias = \", theta[0])\n",
        "print(\"Coefficients = \", theta[1:])\n",
        "\n",
        "# visualising gradient descent\n",
        "plt.plot(error_list)\n",
        "plt.xlabel(\"Number of iterations\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# predicting output for X_test\n",
        "y_pred = hypothesis(X_test, theta)\n",
        "plt.scatter(X_test[:, 1], y_test[:, ], marker='.')\n",
        "plt.plot(X_test[:, 1], y_pred, color='orange')\n",
        "plt.show()\n",
        "\n",
        "# calculating error in predictions\n",
        "error = '...'\n",
        "\n"
      ],
      "metadata": {
        "id": "Oz46YIVYseN0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}